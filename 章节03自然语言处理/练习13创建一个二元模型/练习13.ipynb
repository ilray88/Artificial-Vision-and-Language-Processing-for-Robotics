{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Exercise04.ipynb",
   "version": "0.3.2",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "cells": [
  {
   "metadata": {
    "id": "q-IFBUAMvb-s",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "corpus = [\n",
    "     'My cat is white',\n",
    "     'I am the major of this city',\n",
    "     'I love eating toasted cheese',\n",
    "     'The lazy cat is sleeping',\n",
    "]\n"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "id": "IsJ3Jshzviit",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "nlp = en_core_web_sm.load()\n"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'en_core_web_sm'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_10544/2379817774.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mspacy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0men_core_web_sm\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mspacy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlang\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0men\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstop_words\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSTOP_WORDS\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mnlp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0men_core_web_sm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'en_core_web_sm'"
     ]
    }
   ]
  },
  {
   "metadata": {
    "id": "zhHHdlXSwo_i",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "tokens = []\n",
    "tokens_doc = []\n",
    "distinc_tokens = []\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "r96TyYZjwqfY",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "for c in corpus:\n",
    "    doc = nlp(c)\n",
    "    tokens_aux = []\n",
    "    for t in doc:\n",
    "        tokens_aux.append(t.text)\n",
    "        if t.text not in tokens:\n",
    "            distinc_tokens.append(t.text) # without duplicates\n",
    "        tokens.append(t.text)\n",
    "    tokens_doc.append(tokens_aux)\n",
    "    tokens_aux = []"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "OgoPfqjGwsEg",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "outputId": "a55ddf46-41b2-4c54-f0df-f4bb97dd3997"
   },
   "cell_type": "code",
   "source": [
    "print(tokens)\n",
    "print(distinc_tokens)\n",
    "print(tokens_doc)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "XumQXL2Nw9Cy",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "2602b9a1-65b6-4d04-c004-7754f6880adc"
   },
   "cell_type": "code",
   "source": [
    "def unigram_model(word):\n",
    "    return tokens.count(word)/len(tokens)\n",
    "unigram_model(\"cat\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "LwvagHEUxToe",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "d886a26a-2921-49ef-8a0a-652a1d8bff87"
   },
   "cell_type": "code",
   "source": [
    "def unigram_model_smoothing(word):\n",
    "    return (tokens.count(word) + 1)/(len(tokens) + len(distinc_tokens))\n",
    "unigram_model_smoothing(\"cat\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "SYJvHpIBxYM-",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "outputId": "909553cf-14cb-424c-d9ab-e3659ed5d7e9"
   },
   "cell_type": "code",
   "source": [
    "def bigram_model(word1, word2):\n",
    "    hit = 0\n",
    "    for d in tokens_doc:\n",
    "        for t,i in zip(d, range(len(d))): # i is the length of d\n",
    "            if i <= len(d)-2: \n",
    "                if word1 == d[i] and word2 == d[i+1]:\n",
    "                    hit += 1\n",
    "    print(\"Hits: \",hit)\n",
    "    return hit/tokens.count(word1)\n",
    "bigram_model(\"I\",\"am\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "-H6_aRM4xa6H",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "outputId": "66e9de04-649d-40d8-8ed6-a4d42abf91f3"
   },
   "cell_type": "code",
   "source": [
    "def bigram_model_smoothing(word1, word2):\n",
    "    hit = 0\n",
    "    for d in tokens_doc:\n",
    "        for t,i in zip(d, range(len(d))):\n",
    "            if i <= len(d)-2:\n",
    "                if word1 == d[i] and word2 == d[i+1]:\n",
    "                    hit += 1\n",
    "    return (hit+1)/(tokens.count(word1)+len(distinc_tokens))\n",
    "bigram_model(\"I\",\"am\")\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}